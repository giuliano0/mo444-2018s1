diff --git a/inference_usbCam_face.py b/inference_usbCam_face.py
index 5855642..e3b0ee1 100644
--- a/inference_usbCam_face.py
+++ b/inference_usbCam_face.py
@@ -30,8 +30,10 @@ class TensoflowFaceDector(object):
         """
 
         self.detection_graph = tf.Graph()
+
         with self.detection_graph.as_default():
             od_graph_def = tf.GraphDef()
+
             with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
                 serialized_graph = fid.read()
                 od_graph_def.ParseFromString(serialized_graph)
@@ -41,9 +43,13 @@ class TensoflowFaceDector(object):
         with self.detection_graph.as_default():
             config = tf.ConfigProto()
             config.gpu_options.allow_growth = True
-            with tf.Session(graph=self.detection_graph, config=config) as self.sess:
 
-                self.windowNotSet = True
+            self.sess = tf.Session(graph=self.detection_graph, config=config)
+            self.windowNotSet = True
+
+            # shitty code
+            #with tf.Session(graph=self.detection_graph, config=config) as self.sess:
+            #    self.windowNotSet = True
 
 
     def run(self, image):
@@ -79,11 +85,7 @@ class TensoflowFaceDector(object):
 if __name__ == "__main__":
     import sys
     if len(sys.argv) != 2:
-        print """usage:%s (cameraID | filename)
-Detect faces in the video
-example:
-%s 0
-""" % (sys.argv[0], sys.argv[0])
+        print("usage:%s (cameraID | filename)\nDetect faces in the video\nexample:\n\t%s 0" % (sys.argv[0], sys.argv[0]))
         exit(1)
 
     try:
@@ -101,7 +103,7 @@ example:
             break
 
         [h, w] = image.shape[:2]
-        print h, w
+        print(h, w)
         image = cv2.flip(image, 1)
 
         (boxes, scores, classes, num_detections) = tDetector.run(image)
